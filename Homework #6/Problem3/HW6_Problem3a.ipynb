{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HMnSqDWvTjWI",
        "outputId": "4f36a6d4-2dab-4dfe-8af5-1aa740040289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:16<00:00, 10.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 50000\n",
            "Test samples : 10000\n",
            "FCNetOneHidden(\n",
            "  (fc1): Linear(in_features=3072, out_features=512, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch [01/30] | Time: 15.06s | Train Loss: 1.7003 | Test Accuracy: 45.58%\n",
            "Epoch [02/30] | Time: 13.19s | Train Loss: 1.4675 | Test Accuracy: 47.71%\n",
            "Epoch [03/30] | Time: 13.27s | Train Loss: 1.3872 | Test Accuracy: 48.66%\n",
            "Epoch [04/30] | Time: 13.19s | Train Loss: 1.3129 | Test Accuracy: 49.69%\n",
            "Epoch [05/30] | Time: 13.19s | Train Loss: 1.2582 | Test Accuracy: 49.30%\n",
            "Epoch [06/30] | Time: 13.02s | Train Loss: 1.2046 | Test Accuracy: 51.11%\n",
            "Epoch [07/30] | Time: 13.15s | Train Loss: 1.1548 | Test Accuracy: 50.04%\n",
            "Epoch [08/30] | Time: 13.05s | Train Loss: 1.1078 | Test Accuracy: 51.02%\n",
            "Epoch [09/30] | Time: 13.42s | Train Loss: 1.0651 | Test Accuracy: 50.64%\n",
            "Epoch [10/30] | Time: 13.50s | Train Loss: 1.0019 | Test Accuracy: 51.90%\n",
            "Epoch [11/30] | Time: 14.02s | Train Loss: 0.9683 | Test Accuracy: 50.65%\n",
            "Epoch [12/30] | Time: 13.36s | Train Loss: 0.9258 | Test Accuracy: 51.05%\n",
            "Epoch [13/30] | Time: 13.42s | Train Loss: 0.8862 | Test Accuracy: 52.27%\n",
            "Epoch [14/30] | Time: 13.40s | Train Loss: 0.8375 | Test Accuracy: 51.42%\n",
            "Epoch [15/30] | Time: 13.24s | Train Loss: 0.8050 | Test Accuracy: 51.87%\n",
            "Epoch [16/30] | Time: 13.21s | Train Loss: 0.7555 | Test Accuracy: 51.05%\n",
            "Epoch [17/30] | Time: 13.46s | Train Loss: 0.7414 | Test Accuracy: 50.85%\n",
            "Epoch [18/30] | Time: 13.24s | Train Loss: 0.7133 | Test Accuracy: 52.69%\n",
            "Epoch [19/30] | Time: 13.90s | Train Loss: 0.6572 | Test Accuracy: 52.45%\n",
            "Epoch [20/30] | Time: 14.09s | Train Loss: 0.6428 | Test Accuracy: 52.69%\n",
            "Epoch [21/30] | Time: 13.62s | Train Loss: 0.6244 | Test Accuracy: 52.45%\n",
            "Epoch [22/30] | Time: 13.53s | Train Loss: 0.5923 | Test Accuracy: 51.39%\n",
            "Epoch [23/30] | Time: 13.45s | Train Loss: 0.5829 | Test Accuracy: 50.72%\n",
            "Epoch [24/30] | Time: 13.44s | Train Loss: 0.5758 | Test Accuracy: 50.62%\n",
            "Epoch [25/30] | Time: 13.39s | Train Loss: 0.5412 | Test Accuracy: 51.15%\n",
            "Epoch [26/30] | Time: 13.22s | Train Loss: 0.5045 | Test Accuracy: 50.97%\n",
            "Epoch [27/30] | Time: 13.54s | Train Loss: 0.4702 | Test Accuracy: 50.76%\n",
            "Epoch [28/30] | Time: 13.73s | Train Loss: 0.4721 | Test Accuracy: 52.05%\n",
            "Epoch [29/30] | Time: 13.54s | Train Loss: 0.4687 | Test Accuracy: 51.65%\n",
            "Epoch [30/30] | Time: 13.20s | Train Loss: 0.4578 | Test Accuracy: 51.33%\n",
            "\n",
            "Training finished.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# Problem 3(a) - CIFAR-10 Fully Connected NN\n",
        "# Mohammadmilad_Sayyad\n",
        "# ============================================\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# ------------------------\n",
        "# 1. Device configuration\n",
        "# ------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------------\n",
        "# 2. Hyperparameters\n",
        "# ------------------------\n",
        "input_dim   = 32 * 32 * 3   # CIFAR-10 images: 3 x 32 x 32\n",
        "hidden_dim  = 512           # as required\n",
        "num_classes = 10\n",
        "batch_size  = 128\n",
        "num_epochs  = 30            # you can increase/decrease if you want\n",
        "learning_rate = 0.001\n",
        "\n",
        "# ------------------------\n",
        "# 3. CIFAR-10 Dataset\n",
        "# ------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Test samples :\", len(test_dataset))\n",
        "\n",
        "# ------------------------\n",
        "# 4. Fully Connected Model\n",
        "# ------------------------\n",
        "class FCNetOneHidden(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(FCNetOneHidden, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, 3, 32, 32)\n",
        "        x = x.view(x.size(0), -1)  # flatten to (batch_size, 3072)\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)       # logits\n",
        "        return out\n",
        "\n",
        "model = FCNetOneHidden(input_dim, hidden_dim, num_classes).to(device)\n",
        "print(model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# ------------------------\n",
        "# 5. Training & Evaluation\n",
        "# ------------------------\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        total_batches += 1\n",
        "\n",
        "    # Average training loss\n",
        "    avg_train_loss = running_loss / total_batches\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Evaluation accuracy on test set\n",
        "    test_acc = evaluate(model, test_loader, device)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    # Epoch time\n",
        "    epoch_time = time.time() - start_time\n",
        "    epoch_times.append(epoch_time)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1:02d}/{num_epochs}] | \"\n",
        "          f\"Time: {epoch_time:.2f}s | \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "          f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "\n",
        "# Optionally, you can save train_losses, test_accuracies, and epoch_times\n",
        "# to a file or plot them for your report.\n"
      ]
    }
  ]
}